"use client";
import { useEffect, useState, useRef } from "react";
import { useChatStream } from "@/features/chat/hooks/useChatStream";
import ChatHeader from "@/features/chat/components/ChatHeader";
import MessageList from "@/features/chat/components/MessageList";
import ModelSelect from "@/features/chat/components/ModelSelect";
import InputBar from "@/features/chat/components/InputBar";

import type { Message } from "@/features/chat/types";

export default function Home() {
  const [message, setMessage] = useState("");
  const { messages, isTyping, send, lastAnimatedIdRef, setMessages } = useChatStream();
  const [models, setModels] = useState<string[]>([]);
  const [selectedModel, setSelectedModel] = useState<string>("hf.co/unsloth/gemma-3-270m-it-GGUF:Q8_K_XL");
  const messagesContainerRef = useRef<HTMLDivElement>(null);
  

  useEffect(() => {
    messagesContainerRef.current?.lastElementChild?.scrollIntoView({ behavior: "smooth" });
  }, [messages]);

  useEffect(() => {
    // Load available models from Ollama
    const loadModels = async () => {
      try {
        const res = await fetch('/api/models');
        const data = await res.json();
        type OllamaModel = { name: string };
        const list = ((data?.models as OllamaModel[] | undefined) ?? []).map((m) => m.name).filter(Boolean);
        if (list.length) {
          setModels(list);
          setSelectedModel((prev) => (prev && list.includes(prev) ? prev : list[0]));
        }
      } catch (e) {
        console.warn('Failed to load models', e);
      }
    };
    loadModels();
  }, []);

  useEffect(() => {
    if (!messagesContainerRef.current) return;
    const lastAssistant = [...messages].reverse().find((m) => m.role === "assistant");
    if (!lastAssistant) return;
    if (lastAnimatedIdRef.current === lastAssistant.id) return;
    const bubbles = messagesContainerRef.current.querySelectorAll(".message-bubble");
    if (!bubbles.length) return;
    const lastBubble = bubbles[bubbles.length - 1] as Element;
    // trigger CSS transition already present; anime handled inside MessageList previously
    lastBubble.classList.add('shimmer');
    lastAnimatedIdRef.current = lastAssistant.id;
  }, [messages]);

  // suggestion animation handled inside SuggestionChips

  useEffect(() => {
    // Add welcome message with markdown example
    const welcomeMessage: Message = {
      id: "welcome",
      role: "assistant",
      content: `ðŸ‘‹ **ChÃ o báº¡n!** TÃ´i lÃ  trá»£ lÃ½ AI thÃ´ng minh cá»§a báº¡n.

TÃ´i cÃ³ thá»ƒ giÃºp báº¡n:
- ðŸ“ **Quáº£n lÃ½ cÃ´ng viá»‡c** vÃ  láº­p káº¿ hoáº¡ch
- ðŸ§  **Há»— trá»£ táº­p trung** vá»›i cÃ¡c ká»¹ thuáº­t ADHD
- ðŸ’¡ **Táº¡o Ã½ tÆ°á»Ÿng** vÃ  brainstorming
- ðŸ“Š **PhÃ¢n tÃ­ch thÃ´ng tin** vÃ  tá»•ng há»£p

**CÃ¡ch sá»­ dá»¥ng:**
- Gá»­i tin nháº¯n bÃ¬nh thÆ°á»ng Ä‘á»ƒ trÃ² chuyá»‡n
- Sá»­ dá»¥ng markdown Ä‘á»ƒ format text: **in Ä‘áº­m**, *in nghiÃªng*, \`code\`
- Táº¡o danh sÃ¡ch, báº£ng biá»ƒu vÃ  nhiá»u hÆ¡n ná»¯a!

HÃ£y báº¯t Ä‘áº§u báº±ng cÃ¡ch há»i tÃ´i báº¥t cá»© Ä‘iá»u gÃ¬ báº¡n cáº§n há»— trá»£ nhÃ©! ðŸš€`,
      timestamp: new Date(),
    };
    setMessages([welcomeMessage]);
  }, []);

  const sendMessage = async () => {
    const text = message;
    setMessage("");
    await send(selectedModel, text);
  };

  

  return (
    <div className="chat-container">
      <div className="chat-wrapper">
        <div className="flex-shrink-0">
          <ChatHeader />
        </div>

        <div className="flex-1 min-h-0">
          <MessageList messages={messages} containerRef={messagesContainerRef} lastAnimatedIdRef={lastAnimatedIdRef} />
        </div>

        <div className="flex-shrink-0">
          <InputBar 
            value={message} 
            onChange={setMessage} 
            onSubmit={sendMessage} 
            disabled={isTyping}
            models={models}
            selectedModel={selectedModel}
            onModelChange={setSelectedModel}
          />
        </div>
      </div>
    </div>
  );
}